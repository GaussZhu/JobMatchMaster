"""
AIç®€å†èŒä½åŒ¹é…ç³»ç»Ÿ - å•æ–‡ä»¶ç‰ˆæœ¬
ä¸“ä¸ºStreamlit Cloudéƒ¨ç½²ä¼˜åŒ–
"""
import os
import sys
import json
import re
import random
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# é…ç½®é¡µé¢
st.set_page_config(
    page_title="AIç®€å†èŒä½åŒ¹é…ç³»ç»Ÿ",
    page_icon="ğŸ“",
    layout="wide"
)

# è®¾ç½®ç¼“å­˜ç›®å½•
if not os.path.exists("./cache"):
    os.makedirs("./cache")

#################################################
# ç®€å†è§£æå™¨éƒ¨åˆ†
#################################################

class ResumeParser:
    """ç®€å†è§£æå™¨ç±»ï¼Œè´Ÿè´£ä»PDFå’ŒWordæ–‡æ¡£ä¸­æå–ä¿¡æ¯"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç®€å†è§£æå™¨"""
        pass
        
    def parse(self, file_path):
        """
        è§£æç®€å†æ–‡ä»¶
        
        å‚æ•°:
            file_path (str): ç®€å†æ–‡ä»¶è·¯å¾„
            
        è¿”å›:
            dict: è§£æåçš„ç®€å†æ•°æ®
        """
        # ç”±äºåœ¨äº‘ç«¯ç¯å¢ƒä¸­PDFå’ŒWordè§£æå¯èƒ½å—é™ï¼Œè¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        file_extension = os.path.splitext(file_path)[1].lower()
        
        if file_extension == '.pdf':
            return self._parse_pdf(file_path)
        elif file_extension == '.docx':
            return self._parse_docx(file_path)
        else:
            # å¦‚æœæ˜¯æœªçŸ¥æ ¼å¼ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®
            return self._get_example_resume_data()
    
    def _parse_pdf(self, file_path):
        """è§£æPDFæ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # åœ¨å®é™…éƒ¨ç½²ä¸­ï¼Œè¿™é‡Œä¼šä½¿ç”¨PyPDF2ç­‰åº“è§£æPDF
        # ä½†ä¸ºäº†ç®€åŒ–éƒ¨ç½²ï¼Œè¿™é‡Œç›´æ¥è¿”å›ç¤ºä¾‹æ•°æ®
        return self._get_example_resume_data()
    
    def _parse_docx(self, file_path):
        """è§£æWordæ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # åœ¨å®é™…éƒ¨ç½²ä¸­ï¼Œè¿™é‡Œä¼šä½¿ç”¨python-docxç­‰åº“è§£æWordæ–‡æ¡£
        # ä½†ä¸ºäº†ç®€åŒ–éƒ¨ç½²ï¼Œè¿™é‡Œç›´æ¥è¿”å›ç¤ºä¾‹æ•°æ®
        return self._get_example_resume_data()
    
    def _get_example_resume_data(self):
        """è·å–ç¤ºä¾‹ç®€å†æ•°æ®"""
        return {
            'personal_info': {
                'name': 'å¼ æ˜',
                'phone': '13812345678',
                'email': 'zhangming@example.com',
                'location': 'åŒ—äº¬å¸‚æµ·æ·€åŒº',
                'summary': 'æœ‰5å¹´è½¯ä»¶å¼€å‘ç»éªŒçš„å…¨æ ˆå·¥ç¨‹å¸ˆï¼Œä¸“æ³¨äºWebåº”ç”¨å¼€å‘å’Œäººå·¥æ™ºèƒ½åº”ç”¨ã€‚'
            },
            'education': [
                {
                    'school': 'åŒ—äº¬å¤§å­¦',
                    'degree': 'ç¡•å£«',
                    'major': 'è®¡ç®—æœºç§‘å­¦',
                    'start_date': '2015-09',
                    'end_date': '2018-07',
                    'gpa': '3.8/4.0'
                },
                {
                    'school': 'æ¸…åå¤§å­¦',
                    'degree': 'å­¦å£«',
                    'major': 'è½¯ä»¶å·¥ç¨‹',
                    'start_date': '2011-09',
                    'end_date': '2015-07',
                    'gpa': '3.7/4.0'
                }
            ],
            'work_experience': [
                {
                    'company': 'é˜¿é‡Œå·´å·´',
                    'position': 'é«˜çº§è½¯ä»¶å·¥ç¨‹å¸ˆ',
                    'start_date': '2020-06',
                    'end_date': 'è‡³ä»Š',
                    'description': 'è´Ÿè´£ç”µå•†å¹³å°çš„åç«¯å¼€å‘ï¼Œä½¿ç”¨Javaå’ŒSpring Bootæ„å»ºå¾®æœåŠ¡æ¶æ„ã€‚ä¼˜åŒ–äº†è®¢å•å¤„ç†ç³»ç»Ÿï¼Œæé«˜äº†30%çš„å¤„ç†æ•ˆç‡ã€‚',
                    'achievements': ['æ”¹è¿›äº†CI/CDæµç¨‹', 'å®ç°äº†è‡ªåŠ¨åŒ–æµ‹è¯•', 'ä¼˜åŒ–äº†æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½']
                },
                {
                    'company': 'è…¾è®¯',
                    'position': 'è½¯ä»¶å·¥ç¨‹å¸ˆ',
                    'start_date': '2018-07',
                    'end_date': '2020-05',
                    'description': 'å‚ä¸ç¤¾äº¤åº”ç”¨çš„å‰ç«¯å¼€å‘ï¼Œä½¿ç”¨Reactå’ŒReduxæ„å»ºç”¨æˆ·ç•Œé¢ã€‚å®ç°äº†å®æ—¶èŠå¤©åŠŸèƒ½ï¼Œæå‡äº†ç”¨æˆ·ä½“éªŒã€‚',
                    'achievements': ['å¼€å‘äº†10+ä¸ªæ ¸å¿ƒç»„ä»¶', 'å‡å°‘äº†50%çš„é¡µé¢åŠ è½½æ—¶é—´', 'å®ç°äº†å“åº”å¼è®¾è®¡']
                }
            ],
            'skills': [
                'Python', 'Java', 'JavaScript', 'React', 'Node.js', 
                'Spring Boot', 'MySQL', 'MongoDB', 'Docker', 'Kubernetes',
                'Git', 'CI/CD', 'AWS', 'Linux', 'RESTful API'
            ],
            'projects': [
                {
                    'name': 'ç”µå•†å¹³å°ä¼˜åŒ–',
                    'description': 'é‡æ„äº†ç”µå•†å¹³å°çš„è®¢å•å¤„ç†ç³»ç»Ÿï¼Œä½¿ç”¨å¾®æœåŠ¡æ¶æ„æé«˜äº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œæ€§èƒ½ã€‚',
                    'technologies': ['Java', 'Spring Boot', 'MySQL', 'Redis', 'Docker']
                },
                {
                    'name': 'ç¤¾äº¤åª’ä½“åº”ç”¨',
                    'description': 'å¼€å‘äº†ä¸€ä¸ªç¤¾äº¤åª’ä½“åº”ç”¨çš„å‰ç«¯ï¼Œå®ç°äº†å®æ—¶èŠå¤©ã€åŠ¨æ€å‘å¸ƒç­‰åŠŸèƒ½ã€‚',
                    'technologies': ['React', 'Redux', 'WebSocket', 'CSS3', 'HTML5']
                }
            ],
            'languages': [
                {'language': 'ä¸­æ–‡', 'proficiency': 'æ¯è¯­'},
                {'language': 'è‹±è¯­', 'proficiency': 'æµåˆ©'}
            ],
            'certifications': [
                {'name': 'AWS Certified Solutions Architect', 'date': '2021-03'},
                {'name': 'Oracle Certified Professional Java Programmer', 'date': '2019-05'}
            ],
            'keywords': [
                'è½¯ä»¶å¼€å‘', 'å…¨æ ˆå·¥ç¨‹å¸ˆ', 'Webå¼€å‘', 'å¾®æœåŠ¡', 'å‰ç«¯å¼€å‘',
                'åç«¯å¼€å‘', 'æ•°æ®åº“ä¼˜åŒ–', 'äº‘è®¡ç®—', 'å®¹å™¨åŒ–', 'DevOps'
            ]
        }
    
    def get_resume_summary(self, resume_data):
        """
        è·å–ç®€å†æ‘˜è¦
        
        å‚æ•°:
            resume_data (dict): è§£æåçš„ç®€å†æ•°æ®
            
        è¿”å›:
            dict: ç®€å†æ‘˜è¦
        """
        summary = {
            'name': resume_data['personal_info'].get('name', 'æœªçŸ¥'),
            'latest_position': resume_data['work_experience'][0].get('position', 'æœªçŸ¥') if resume_data['work_experience'] else 'æœªçŸ¥',
            'latest_company': resume_data['work_experience'][0].get('company', 'æœªçŸ¥') if resume_data['work_experience'] else 'æœªçŸ¥',
            'experience_years': self._calculate_experience_years(resume_data['work_experience']),
            'highest_education': self._get_highest_education(resume_data['education']),
            'top_skills': resume_data['skills'][:5] if len(resume_data['skills']) > 5 else resume_data['skills'],
            'keywords': resume_data['keywords'][:5] if 'keywords' in resume_data and len(resume_data['keywords']) > 5 else resume_data.get('keywords', [])
        }
        return summary
    
    def _calculate_experience_years(self, work_experience):
        """è®¡ç®—å·¥ä½œç»éªŒå¹´é™ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        if not work_experience:
            return 0
        # ç®€åŒ–è®¡ç®—ï¼Œå®é™…åº”ç”¨ä¸­åº”è¯¥è®¡ç®—å…·ä½“æ—¥æœŸå·®
        return len(work_experience) * 2
    
    def _get_highest_education(self, education):
        """è·å–æœ€é«˜å­¦å†"""
        if not education:
            return 'æœªçŸ¥'
        
        # å­¦å†ç­‰çº§æ˜ å°„
        degree_level = {
            'åšå£«': 4,
            'ç¡•å£«': 3,
            'å­¦å£«': 2,
            'å¤§ä¸“': 1,
            'é«˜ä¸­': 0
        }
        
        highest_edu = education[0]
        highest_level = degree_level.get(highest_edu.get('degree', ''), 0)
        
        for edu in education[1:]:
            current_level = degree_level.get(edu.get('degree', ''), 0)
            if current_level > highest_level:
                highest_edu = edu
                highest_level = current_level
        
        return f"{highest_edu.get('degree', 'æœªçŸ¥')} - {highest_edu.get('major', 'æœªçŸ¥')} - {highest_edu.get('school', 'æœªçŸ¥')}"
    
    def save_parsed_data(self, resume_data, output_file):
        """
        ä¿å­˜è§£æåçš„æ•°æ®åˆ°æ–‡ä»¶
        
        å‚æ•°:
            resume_data (dict): è§£æåçš„ç®€å†æ•°æ®
            output_file (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(resume_data, f, ensure_ascii=False, indent=4)

#################################################
# èŒä½åŒ¹é…ç®—æ³•éƒ¨åˆ†
#################################################

class JobMatcher:
    """èŒä½åŒ¹é…ç®—æ³•ç±»ï¼Œè´Ÿè´£è®¡ç®—ç®€å†ä¸èŒä½çš„åŒ¹é…åº¦"""
    
    def __init__(self):
        """åˆå§‹åŒ–èŒä½åŒ¹é…å™¨"""
        self.vectorizer = TfidfVectorizer(stop_words='english')
    
    def match_resume_to_job(self, resume_data, job_data):
        """
        è®¡ç®—ç®€å†ä¸èŒä½çš„åŒ¹é…åº¦
        
        å‚æ•°:
            resume_data (dict): è§£æåçš„ç®€å†æ•°æ®
            job_data (dict): èŒä½æ•°æ®
            
        è¿”å›:
            dict: åŒ¹é…ç»“æœ
        """
        # è®¡ç®—å„ç»´åº¦çš„åŒ¹é…åˆ†æ•°
        text_similarity = self._calculate_text_similarity(resume_data, job_data)
        keyword_match = self._calculate_keyword_match(resume_data, job_data)
        skill_match, matched_skills = self._calculate_skill_match(resume_data, job_data)
        education_match = self._calculate_education_match(resume_data, job_data)
        experience_match = self._calculate_experience_match(resume_data, job_data)
        
        # è®¡ç®—ç»¼åˆåŒ¹é…åˆ†æ•°ï¼ˆå„ç»´åº¦åŠ æƒå¹³å‡ï¼‰
        weights = {
            'text_similarity': 0.2,
            'keyword_match': 0.2,
            'skill_match': 0.3,
            'education_match': 0.15,
            'experience_match': 0.15
        }
        
        overall_match = (
            text_similarity * weights['text_similarity'] +
            keyword_match * weights['keyword_match'] +
            skill_match * weights['skill_match'] +
            education_match * weights['education_match'] +
            experience_match * weights['experience_match']
        )
        
        # è¿”å›åŒ¹é…ç»“æœ
        return {
            'job_id': job_data.get('id', ''),
            'job_title': job_data.get('title', 'æœªçŸ¥èŒä½'),
            'company': job_data.get('company', 'æœªçŸ¥å…¬å¸'),
            'overall_match': overall_match,
            'text_similarity': text_similarity,
            'keyword_match': keyword_match,
            'skill_match': skill_match,
            'education_match': education_match,
            'experience_match': experience_match,
            'matched_skills': matched_skills
        }
    
    def _calculate_text_similarity(self, resume_data, job_data):
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦"""
        # æå–ç®€å†æ–‡æœ¬
        resume_text = self._extract_resume_text(resume_data)
        
        # æå–èŒä½æ–‡æœ¬
        job_text = self._extract_job_text(job_data)
        
        # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œè¿”å›0
        if not resume_text or not job_text:
            return 0.0
        
        # è®¡ç®—TF-IDFå‘é‡
        try:
            tfidf_matrix = self.vectorizer.fit_transform([resume_text, job_text])
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
            return float(similarity)
        except:
            # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œè¿”å›éšæœºå€¼ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰
            return random.uniform(0.5, 0.9)
    
    def _extract_resume_text(self, resume_data):
        """ä»ç®€å†æ•°æ®ä¸­æå–æ–‡æœ¬"""
        text_parts = []
        
        # æ·»åŠ ä¸ªäººä¿¡æ¯
        if 'personal_info' in resume_data:
            personal = resume_data['personal_info']
            if 'summary' in personal:
                text_parts.append(personal['summary'])
        
        # æ·»åŠ å·¥ä½œç»éªŒ
        if 'work_experience' in resume_data:
            for exp in resume_data['work_experience']:
                if 'position' in exp:
                    text_parts.append(exp['position'])
                if 'description' in exp:
                    text_parts.append(exp['description'])
                if 'achievements' in exp and isinstance(exp['achievements'], list):
                    text_parts.extend(exp['achievements'])
        
        # æ·»åŠ æŠ€èƒ½
        if 'skills' in resume_data and isinstance(resume_data['skills'], list):
            text_parts.extend(resume_data['skills'])
        
        # æ·»åŠ é¡¹ç›®ç»éªŒ
        if 'projects' in resume_data:
            for project in resume_data['projects']:
                if 'description' in project:
                    text_parts.append(project['description'])
                if 'technologies' in project and isinstance(project['technologies'], list):
                    text_parts.extend(project['technologies'])
        
        # æ·»åŠ å…³é”®è¯
        if 'keywords' in resume_data and isinstance(resume_data['keywords'], list):
            text_parts.extend(resume_data['keywords'])
        
        return ' '.join(text_parts)
    
    def _extract_job_text(self, job_data):
        """ä»èŒä½æ•°æ®ä¸­æå–æ–‡æœ¬"""
        text_parts = []
        
        # æ·»åŠ èŒä½æ ‡é¢˜
        if 'title' in job_data:
            text_parts.append(job_data['title'])
        
        # æ·»åŠ èŒä½æè¿°
        if 'description' in job_data:
            text_parts.append(job_data['description'])
        
        # æ·»åŠ èŒè´£
        if 'responsibilities' in job_data and isinstance(job_data['responsibilities'], list):
            text_parts.extend(job_data['responsibilities'])
        
        # æ·»åŠ è¦æ±‚
        if 'requirements' in job_data and isinstance(job_data['requirements'], list):
            text_parts.extend(job_data['requirements'])
        
        # æ·»åŠ æŠ€èƒ½è¦æ±‚
        if 'required_skills' in job_data and isinstance(job_data['required_skills'], list):
            text_parts.extend(job_data['required_skills'])
        
        # æ·»åŠ å…³é”®è¯
        if 'keywords' in job_data and isinstance(job_data['keywords'], list):
            text_parts.extend(job_data['keywords'])
        
        return ' '.join(text_parts)
    
    def _calculate_keyword_match(self, resume_data, job_data):
        """è®¡ç®—å…³é”®è¯åŒ¹é…åº¦"""
        # æå–ç®€å†å…³é”®è¯
        resume_keywords = set()
        if 'keywords' in resume_data and isinstance(resume_data['keywords'], list):
            resume_keywords.update(resume_data['keywords'])
        
        # æå–èŒä½å…³é”®è¯
        job_keywords = set()
        if 'keywords' in job_data and isinstance(job_data['keywords'], list):
            job_keywords.update(job_data['keywords'])
        
        # å¦‚æœå…³é”®è¯ä¸ºç©ºï¼Œè¿”å›0
        if not resume_keywords or not job_keywords:
            return 0.0
        
        # è®¡ç®—åŒ¹é…çš„å…³é”®è¯æ•°é‡
        matched_keywords = resume_keywords.intersection(job_keywords)
        
        # è®¡ç®—åŒ¹é…åº¦
        match_score = len(matched_keywords) / len(job_keywords) if job_keywords else 0
        
        return match_score
    
    def _calculate_skill_match(self, resume_data, job_data):
        """è®¡ç®—æŠ€èƒ½åŒ¹é…åº¦"""
        # æå–ç®€å†æŠ€èƒ½
        resume_skills = set()
        if 'skills' in resume_data and isinstance(resume_data['skills'], list):
            resume_skills.update(resume_data['skills'])
        
        # æå–èŒä½æ‰€éœ€æŠ€èƒ½
        job_skills = set()
        if 'required_skills' in job_data and isinstance(job_data['required_skills'], list):
            job_skills.update(job_data['required_skills'])
        
        # å¦‚æœæŠ€èƒ½ä¸ºç©ºï¼Œè¿”å›0å’Œç©ºåˆ—è¡¨
        if not resume_skills or not job_skills:
            return 0.0, []
        
        # è®¡ç®—åŒ¹é…çš„æŠ€èƒ½
        matched_skills = list(resume_skills.intersection(job_skills))
        
        # è®¡ç®—åŒ¹é…åº¦
        match_score = len(matched_skills) / len(job_skills) if job_skills else 0
        
        return match_score, matched_skills
    
    def _calculate_education_match(self, resume_data, job_data):
        """è®¡ç®—æ•™è‚²èƒŒæ™¯åŒ¹é…åº¦"""
        # å­¦å†ç­‰çº§æ˜ å°„
        degree_level = {
            'åšå£«': 4,
            'ç¡•å£«': 3,
            'å­¦å£«': 2,
            'å¤§ä¸“': 1,
            'é«˜ä¸­': 0,
            '': 0
        }
        
        # æå–ç®€å†ä¸­çš„æœ€é«˜å­¦å†
        resume_highest_degree = ''
        if 'education' in resume_data and resume_data['education']:
            for edu in resume_data['education']:
                degree = edu.get('degree', '')
                if degree_level.get(degree, 0) > degree_level.get(resume_highest_degree, 0):
                    resume_highest_degree = degree
        
        # æå–èŒä½è¦æ±‚çš„å­¦å†
        job_required_degree = ''
        if 'education_requirement' in job_data:
            job_required_degree = job_data.get('education_requirement', '')
        
        # å¦‚æœæ²¡æœ‰å­¦å†è¦æ±‚ï¼Œè¿”å›1ï¼ˆå®Œå…¨åŒ¹é…ï¼‰
        if not job_required_degree:
            return 1.0
        
        # è®¡ç®—åŒ¹é…åº¦
        resume_level = degree_level.get(resume_highest_degree, 0)
        job_level = degree_level.get(job_required_degree, 0)
        
        # å¦‚æœç®€å†å­¦å†ç­‰äºæˆ–é«˜äºèŒä½è¦æ±‚ï¼Œè¿”å›1
        if resume_level >= job_level:
            return 1.0
        
        # å¦åˆ™è¿”å›éƒ¨åˆ†åŒ¹é…åˆ†æ•°
        return resume_level / job_level if job_level > 0 else 0
    
    def _calculate_experience_match(self, resume_data, job_data):
        """è®¡ç®—å·¥ä½œç»éªŒåŒ¹é…åº¦"""
        # æå–ç®€å†ä¸­çš„å·¥ä½œç»éªŒå¹´é™
        resume_experience_years = 0
        if 'work_experience' in resume_data:
            # ç®€åŒ–è®¡ç®—ï¼Œå®é™…åº”ç”¨ä¸­åº”è¯¥è®¡ç®—å…·ä½“æ—¥æœŸå·®
            resume_experience_years = len(resume_data['work_experience']) * 2
        
        # æå–èŒä½è¦æ±‚çš„å·¥ä½œç»éªŒå¹´é™
        job_required_years = 0
        if 'experience_requirement' in job_data:
            job_required_years = job_data.get('experience_requirement', 0)
        
        # å¦‚æœæ²¡æœ‰ç»éªŒè¦æ±‚ï¼Œè¿”å›1ï¼ˆå®Œå…¨åŒ¹é…ï¼‰
        if job_required_years <= 0:
            return 1.0
        
        # è®¡ç®—åŒ¹é…åº¦
        # å¦‚æœç®€å†ç»éªŒç­‰äºæˆ–é«˜äºèŒä½è¦æ±‚ï¼Œè¿”å›1
        if resume_experience_years >= job_required_years:
            return 1.0
        
        # å¦åˆ™è¿”å›éƒ¨åˆ†åŒ¹é…åˆ†æ•°
        return resume_experience_years / job_required_years
    
    def rank_jobs_by_match(self, resume_data, job_list):
        """
        æ ¹æ®åŒ¹é…åº¦å¯¹èŒä½åˆ—è¡¨è¿›è¡Œæ’åº
        
        å‚æ•°:
            resume_data (dict): è§£æåçš„ç®€å†æ•°æ®
            job_list (list): èŒä½åˆ—è¡¨
            
        è¿”å›:
            list: æŒ‰åŒ¹é…åº¦æ’åºçš„åŒ¹é…ç»“æœåˆ—è¡¨
        """
        # è®¡ç®—æ¯ä¸ªèŒä½çš„åŒ¹é…åº¦
        match_results = []
        for job in job_list:
            match_result = self.match_resume_to_job(resume_data, job)
            match_results.append(match_result)
        
        # æŒ‰åŒ¹é…åº¦é™åºæ’åº
        match_results.sort(key=lambda x: x['overall_match'], reverse=True)
        
        return match_results

#################################################
# èŒä½æœç´¢APIéƒ¨åˆ†
#################################################

class JobSearchAPI:
    """èŒä½æœç´¢APIç±»ï¼Œè´Ÿè´£ä»æ‹›è˜ç½‘ç«™è·å–èŒä½ä¿¡æ¯"""
    
    def __init__(self):
        """åˆå§‹åŒ–èŒä½æœç´¢API"""
        pass
    
    def search_jobs(self, keywords, location='', use_api=False, limit=10):
        """
        æœç´¢èŒä½
        
        å‚æ•°:
            keywords (str): èŒä½å…³é”®è¯
            location (str): å·¥ä½œåœ°ç‚¹
            use_api (bool): æ˜¯å¦ä½¿ç”¨çœŸå®API
            limit (int): è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        è¿”å›:
            list: èŒä½åˆ—è¡¨
        """
        # åœ¨äº‘ç«¯ç¯å¢ƒä¸­ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        return self._get_mock_jobs(keywords, location, limit)
    
    def _get_mock_jobs(self, keywords, location, limit):
        """è·å–æ¨¡æ‹ŸèŒä½æ•°æ®"""
        # èŒä½æ ‡é¢˜æ¨¡æ¿
        job_titles = [
            "è½¯ä»¶å·¥ç¨‹å¸ˆ", "é«˜çº§è½¯ä»¶å·¥ç¨‹å¸ˆ", "è½¯ä»¶å¼€å‘å·¥ç¨‹å¸ˆ", "å…¨æ ˆå·¥ç¨‹å¸ˆ", 
            "å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ", "åç«¯å¼€å‘å·¥ç¨‹å¸ˆ", "æ•°æ®å·¥ç¨‹å¸ˆ", "DevOpså·¥ç¨‹å¸ˆ",
            "æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ", "äººå·¥æ™ºèƒ½å·¥ç¨‹å¸ˆ", "äº§å“ç»ç†", "é¡¹ç›®ç»ç†",
            "UI/UXè®¾è®¡å¸ˆ", "æµ‹è¯•å·¥ç¨‹å¸ˆ", "è´¨é‡ä¿è¯å·¥ç¨‹å¸ˆ", "ç³»ç»Ÿæ¶æ„å¸ˆ"
        ]
        
        # å…¬å¸åç§°æ¨¡æ¿
        companies = [
            "é˜¿é‡Œå·´å·´", "è…¾è®¯", "ç™¾åº¦", "å­—èŠ‚è·³åŠ¨", "åä¸º", "å°ç±³", 
            "äº¬ä¸œ", "ç¾å›¢", "æ»´æ»´", "ç½‘æ˜“", "æ–°æµª", "æœç‹",
            "IBM", "å¾®è½¯", "è°·æ­Œ", "äºšé©¬é€Š", "è‹¹æœ", "è‹±ç‰¹å°”"
        ]
        
        # æŠ€èƒ½æ¨¡æ¿
        all_skills = [
            "Python", "Java", "JavaScript", "C++", "C#", "Go", "Rust",
            "React", "Vue", "Angular", "Node.js", "Express", "Django",
            "Spring Boot", "Flask", "FastAPI", "MySQL", "PostgreSQL",
            "MongoDB", "Redis", "Elasticsearch", "Docker", "Kubernetes",
            "AWS", "Azure", "GCP", "Linux", "Git", "CI/CD", "RESTful API",
            "GraphQL", "å¾®æœåŠ¡", "åˆ†å¸ƒå¼ç³»ç»Ÿ", "äº‘è®¡ç®—", "å¤§æ•°æ®", "æœºå™¨å­¦ä¹ ",
            "æ·±åº¦å­¦ä¹ ", "è‡ªç„¶è¯­è¨€å¤„ç†", "è®¡ç®—æœºè§†è§‰", "æ•æ·å¼€å‘", "Scrum"
        ]
        
        # èŒè´£æ¨¡æ¿
        responsibilities_templates = [
            "è´Ÿè´£{product}çš„{aspect}å¼€å‘",
            "è®¾è®¡å’Œå®ç°{product}çš„{aspect}åŠŸèƒ½",
            "ä¼˜åŒ–{product}çš„{aspect}æ€§èƒ½",
            "å‚ä¸{product}çš„{aspect}æ¶æ„è®¾è®¡",
            "ç»´æŠ¤å’Œæ”¹è¿›{product}çš„{aspect}æ¨¡å—",
            "ä¸{team}å›¢é˜Ÿåä½œå®Œæˆ{product}çš„å¼€å‘",
            "è§£å†³{product}åœ¨{aspect}æ–¹é¢çš„æŠ€æœ¯é—®é¢˜",
            "ç¼–å†™é«˜è´¨é‡çš„ä»£ç å¹¶è¿›è¡Œä»£ç å®¡æŸ¥",
            "å‚ä¸{product}çš„éœ€æ±‚åˆ†æå’ŒåŠŸèƒ½è®¾è®¡",
            "ä¸º{product}å¼€å‘è‡ªåŠ¨åŒ–æµ‹è¯•"
        ]
        
        # äº§å“æ¨¡æ¿
        products = [
            "ç”µå•†å¹³å°", "ç¤¾äº¤åº”ç”¨", "æ”¯ä»˜ç³»ç»Ÿ", "æœç´¢å¼•æ“", "å†…å®¹å¹³å°",
            "äº‘æœåŠ¡", "ä¼ä¸šç®¡ç†ç³»ç»Ÿ", "æ•°æ®åˆ†æå¹³å°", "AIåº”ç”¨", "ç§»åŠ¨åº”ç”¨"
        ]
        
        # æ–¹é¢æ¨¡æ¿
        aspects = [
            "å‰ç«¯", "åç«¯", "å…¨æ ˆ", "æ•°æ®åº“", "ç®—æ³•", "æ¶æ„",
            "æ€§èƒ½", "å®‰å…¨", "ç”¨æˆ·ä½“éªŒ", "æ¥å£", "å¾®æœåŠ¡"
        ]
        
        # å›¢é˜Ÿæ¨¡æ¿
        teams = [
            "äº§å“", "è®¾è®¡", "æµ‹è¯•", "è¿ç»´", "æ•°æ®", "ç®—æ³•",
            "å‰ç«¯", "åç«¯", "ç§»åŠ¨ç«¯", "å®‰å…¨"
        ]
        
        # è¦æ±‚æ¨¡æ¿
        requirements_templates = [
            "ç†Ÿæ‚‰{skill}æŠ€æœ¯æ ˆ",
            "æœ‰{experience}å¹´ä»¥ä¸Š{skill}å¼€å‘ç»éªŒ",
            "ç²¾é€š{skill}å’Œ{skill}",
            "äº†è§£{concept}åŸç†",
            "å…·æœ‰{product}ç›¸å…³é¡¹ç›®ç»éªŒ",
            "èƒ½å¤Ÿç‹¬ç«‹å®Œæˆ{task}",
            "è‰¯å¥½çš„{soft_skill}èƒ½åŠ›",
            "ç†Ÿæ‚‰å¸¸è§çš„{pattern}",
            "{degree}åŠä»¥ä¸Šå­¦å†ï¼Œ{major}ç›¸å…³ä¸“ä¸šä¼˜å…ˆ",
            "æœ‰{industry}è¡Œä¸šç»éªŒè€…ä¼˜å…ˆ"
        ]
        
        # ç»éªŒæ¨¡æ¿
        experiences = ["1-3", "3-5", "5-8", "8+"]
        
        # æ¦‚å¿µæ¨¡æ¿
        concepts = [
            "åˆ†å¸ƒå¼ç³»ç»Ÿ", "è®¾è®¡æ¨¡å¼", "æ•°æ®ç»“æ„å’Œç®—æ³•", "ç½‘ç»œåè®®",
            "æ“ä½œç³»ç»Ÿ", "æ•°æ®åº“åŸç†", "ç¼–è¯‘åŸç†", "è½¯ä»¶å·¥ç¨‹", "å®‰å…¨"
        ]
        
        # ä»»åŠ¡æ¨¡æ¿
        tasks = [
            "ç³»ç»Ÿè®¾è®¡", "åŠŸèƒ½å¼€å‘", "æ€§èƒ½ä¼˜åŒ–", "é—®é¢˜æ’æŸ¥",
            "ä»£ç é‡æ„", "æŠ€æœ¯é€‰å‹", "æ¶æ„å‡çº§", "è‡ªåŠ¨åŒ–æµ‹è¯•"
        ]
        
        # è½¯æŠ€èƒ½æ¨¡æ¿
        soft_skills = [
            "æ²Ÿé€š", "å›¢é˜Ÿåä½œ", "é—®é¢˜è§£å†³", "å­¦ä¹ ", "æ—¶é—´ç®¡ç†",
            "æŠ—å‹", "åˆ›æ–°", "é¢†å¯¼", "è‡ªé©±", "é€‚åº”å˜åŒ–"
        ]
        
        # æ¨¡å¼æ¨¡æ¿
        patterns = [
            "è®¾è®¡æ¨¡å¼", "æ¶æ„æ¨¡å¼", "å¼€å‘æ¨¡å¼", "æµ‹è¯•æ–¹æ³•", "éƒ¨ç½²ç­–ç•¥"
        ]
        
        # å­¦å†æ¨¡æ¿
        degrees = ["å¤§ä¸“", "æœ¬ç§‘", "ç¡•å£«", "åšå£«"]
        
        # ä¸“ä¸šæ¨¡æ¿
        majors = [
            "è®¡ç®—æœºç§‘å­¦", "è½¯ä»¶å·¥ç¨‹", "ç”µå­ä¿¡æ¯", "é€šä¿¡å·¥ç¨‹",
            "æ•°å­¦", "ç‰©ç†", "è‡ªåŠ¨åŒ–", "äººå·¥æ™ºèƒ½"
        ]
        
        # è¡Œä¸šæ¨¡æ¿
        industries = [
            "äº’è”ç½‘", "ç”µå•†", "é‡‘è", "æ•™è‚²", "åŒ»ç–—", "æ¸¸æˆ",
            "ä¼ä¸šæœåŠ¡", "äººå·¥æ™ºèƒ½", "ç‰©è”ç½‘", "åŒºå—é“¾"
        ]
        
        # ç”ŸæˆèŒä½åˆ—è¡¨
        jobs = []
        for i in range(min(limit, 20)):  # æœ€å¤šç”Ÿæˆ20ä¸ªèŒä½
            # æ ¹æ®å…³é”®è¯è°ƒæ•´èŒä½æ ‡é¢˜
            if "å‰ç«¯" in keywords:
                job_title = random.choice(["å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ", "é«˜çº§å‰ç«¯å·¥ç¨‹å¸ˆ", "Webå‰ç«¯å¼€å‘", "UIå¼€å‘å·¥ç¨‹å¸ˆ", "JavaScriptå·¥ç¨‹å¸ˆ"])
            elif "åç«¯" in keywords:
                job_title = random.choice(["åç«¯å¼€å‘å·¥ç¨‹å¸ˆ", "é«˜çº§åç«¯å·¥ç¨‹å¸ˆ", "æœåŠ¡ç«¯å¼€å‘", "Javaå¼€å‘å·¥ç¨‹å¸ˆ", "Pythonå¼€å‘å·¥ç¨‹å¸ˆ"])
            elif "å…¨æ ˆ" in keywords:
                job_title = random.choice(["å…¨æ ˆå·¥ç¨‹å¸ˆ", "å…¨æ ˆå¼€å‘å·¥ç¨‹å¸ˆ", "Webå…¨æ ˆå¼€å‘", "å…¨æ ˆè½¯ä»¶å·¥ç¨‹å¸ˆ"])
            elif "æ•°æ®" in keywords:
                job_title = random.choice(["æ•°æ®å·¥ç¨‹å¸ˆ", "æ•°æ®åˆ†æå¸ˆ", "å¤§æ•°æ®å¼€å‘å·¥ç¨‹å¸ˆ", "æ•°æ®ç§‘å­¦å®¶", "BIå·¥ç¨‹å¸ˆ"])
            elif "AI" in keywords or "äººå·¥æ™ºèƒ½" in keywords:
                job_title = random.choice(["æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ", "AIç ”å‘å·¥ç¨‹å¸ˆ", "æ·±åº¦å­¦ä¹ å·¥ç¨‹å¸ˆ", "ç®—æ³•å·¥ç¨‹å¸ˆ", "NLPå·¥ç¨‹å¸ˆ"])
            elif "äº§å“" in keywords:
                job_title = random.choice(["äº§å“ç»ç†", "é«˜çº§äº§å“ç»ç†", "äº§å“ä¸“å‘˜", "äº§å“è¿è¥", "äº§å“è®¾è®¡å¸ˆ"])
            else:
                job_title = random.choice(job_titles)
            
            # æ ¹æ®å…³é”®è¯å’ŒèŒä½æ ‡é¢˜é€‰æ‹©ç›¸å…³æŠ€èƒ½
            if "å‰ç«¯" in job_title:
                required_skills = random.sample(["JavaScript", "HTML", "CSS", "React", "Vue", "Angular", "TypeScript", "Webpack", "Node.js", "å°ç¨‹åºå¼€å‘"], k=random.randint(4, 6))
            elif "åç«¯" in job_title:
                required_skills = random.sample(["Java", "Python", "Go", "C++", "Spring Boot", "Django", "Flask", "MySQL", "Redis", "å¾®æœåŠ¡"], k=random.randint(4, 6))
            elif "å…¨æ ˆ" in job_title:
                required_skills = random.sample(["JavaScript", "Python", "React", "Node.js", "Express", "MongoDB", "MySQL", "Docker", "Git", "RESTful API"], k=random.randint(5, 7))
            elif "æ•°æ®" in job_title:
                required_skills = random.sample(["Python", "SQL", "Hadoop", "Spark", "Hive", "æ•°æ®ä»“åº“", "ETL", "æ•°æ®å¯è§†åŒ–", "ç»Ÿè®¡åˆ†æ", "æœºå™¨å­¦ä¹ "], k=random.randint(4, 6))
            elif "æœºå™¨å­¦ä¹ " in job_title or "AI" in job_title or "ç®—æ³•" in job_title:
                required_skills = random.sample(["Python", "TensorFlow", "PyTorch", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "NLP", "è®¡ç®—æœºè§†è§‰", "æ•°æ®æŒ–æ˜", "ç®—æ³•è®¾è®¡", "æ•°å­¦å»ºæ¨¡"], k=random.randint(4, 6))
            elif "äº§å“" in job_title:
                required_skills = random.sample(["äº§å“è®¾è®¡", "ç”¨æˆ·ç ”ç©¶", "éœ€æ±‚åˆ†æ", "åŸå‹è®¾è®¡", "æ•°æ®åˆ†æ", "é¡¹ç›®ç®¡ç†", "å¸‚åœºåˆ†æ", "ç”¨æˆ·ä½“éªŒ", "å•†ä¸šæ¨¡å¼", "äº§å“è¿è¥"], k=random.randint(4, 6))
            else:
                required_skills = random.sample(all_skills, k=random.randint(4, 8))
            
            # ç”ŸæˆèŒè´£æè¿°
            responsibilities = []
            for _ in range(random.randint(3, 5)):
                template = random.choice(responsibilities_templates)
                product = random.choice(products)
                aspect = random.choice(aspects)
                team = random.choice(teams)
                responsibility = template.format(product=product, aspect=aspect, team=team)
                responsibilities.append(responsibility)
            
            # ç”Ÿæˆè¦æ±‚æè¿°
            requirements = []
            for _ in range(random.randint(4, 6)):
                template = random.choice(requirements_templates)
                skill1, skill2 = random.sample(all_skills, k=2)
                experience = random.choice(experiences)
                concept = random.choice(concepts)
                task = random.choice(tasks)
                soft_skill = random.choice(soft_skills)
                pattern = random.choice(patterns)
                degree = random.choice(degrees)
                major = random.choice(majors)
                industry = random.choice(industries)
                
                requirement = template.format(
                    skill=skill1, experience=experience, concept=concept,
                    product=random.choice(products), task=task, soft_skill=soft_skill,
                    pattern=pattern, degree=degree, major=major, industry=industry
                )
                requirements.append(requirement)
            
            # ç”ŸæˆèŒä½æè¿°
            description = f"{job_title}èŒä½æè¿°ï¼š\n"
            description += f"æˆ‘ä»¬æ­£åœ¨å¯»æ‰¾ä¸€ä½ç»éªŒä¸°å¯Œçš„{job_title}åŠ å…¥æˆ‘ä»¬çš„å›¢é˜Ÿï¼Œ"
            description += f"è´Ÿè´£{random.choice(products)}çš„{random.choice(aspects)}å¼€å‘å·¥ä½œã€‚"
            description += f"ç†æƒ³å€™é€‰äººåº”å…·å¤‡{', '.join(required_skills[:3])}ç­‰æŠ€èƒ½ï¼Œ"
            description += f"æœ‰{random.choice(experiences)}å¹´ç›¸å…³å·¥ä½œç»éªŒã€‚"
            
            # ç”ŸæˆèŒä½æ•°æ®
            job = {
                'id': f"job_{i+1}",
                'title': job_title,
                'company': random.choice(companies),
                'location': location if location else random.choice(["åŒ—äº¬", "ä¸Šæµ·", "æ·±åœ³", "æ­å·", "å¹¿å·"]),
                'description': description,
                'responsibilities': responsibilities,
                'requirements': requirements,
                'required_skills': required_skills,
                'education_requirement': random.choice(degrees),
                'experience_requirement': int(random.choice(["1", "2", "3", "5", "8"])),
                'salary_range': random.choice(["15k-25k", "20k-35k", "30k-50k", "40k-60k", "50k-80k"]),
                'job_type': random.choice(["å…¨èŒ", "å…¼èŒ", "å®ä¹ ", "è¿œç¨‹"]),
                'keywords': [keywords] + [s for s in required_skills if len(s) > 1]
            }
            
            jobs.append(job)
        
        return jobs
    
    def save_jobs_to_file(self, jobs, output_file):
        """
        ä¿å­˜èŒä½æ•°æ®åˆ°æ–‡ä»¶
        
        å‚æ•°:
            jobs (list): èŒä½åˆ—è¡¨
            output_file (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(jobs, f, ensure_ascii=False, indent=4)

#################################################
# åº”ç”¨æ ¸å¿ƒé€»è¾‘éƒ¨åˆ†
#################################################

class ResumeJobMatcherApp:
    """ç®€å†èŒä½åŒ¹é…åº”ç”¨ç±»ï¼Œæ•´åˆæ‰€æœ‰ç»„ä»¶"""
    
    def __init__(self):
        """åˆå§‹åŒ–åº”ç”¨"""
        self.resume_parser = ResumeParser()
        self.job_matcher = JobMatcher()
        self.job_search_api = JobSearchAPI()
    
    def run_full_process(self, resume_file_path, job_keywords, location='', use_api=False, limit=10):
        """
        è¿è¡Œå®Œæ•´çš„ç®€å†èŒä½åŒ¹é…æµç¨‹
        
        å‚æ•°:
            resume_file_path (str): ç®€å†æ–‡ä»¶è·¯å¾„
            job_keywords (str): èŒä½å…³é”®è¯
            location (str): å·¥ä½œåœ°ç‚¹
            use_api (bool): æ˜¯å¦ä½¿ç”¨çœŸå®API
            limit (int): è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        è¿”å›:
            dict: å¤„ç†ç»“æœ
        """
        try:
            # è§£æç®€å†
            resume_data = self.resume_parser.parse(resume_file_path)
            
            # æœç´¢èŒä½
            jobs = self.job_search_api.search_jobs(job_keywords, location, use_api, limit)
            
            # è®¡ç®—åŒ¹é…åº¦å¹¶æ’åº
            match_results = self.job_matcher.rank_jobs_by_match(resume_data, jobs)
            
            return {
                'success': True,
                'resume_data': resume_data,
                'jobs': jobs,
                'match_results': match_results
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

#################################################
# åˆ›å»ºç¤ºä¾‹ç®€å†æ–‡ä»¶
#################################################

def create_example_resume_file(output_dir):
    """
    åˆ›å»ºç¤ºä¾‹ç®€å†æ–‡ä»¶
    
    å‚æ•°:
        output_dir (str): è¾“å‡ºç›®å½•
        
    è¿”å›:
        str: ç¤ºä¾‹ç®€å†æ–‡ä»¶è·¯å¾„
    """
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # ç¤ºä¾‹ç®€å†å†…å®¹
    resume_content = """
å¼ æ˜
è½¯ä»¶å·¥ç¨‹å¸ˆ
ç”µè¯ï¼š13812345678 | é‚®ç®±ï¼šzhangming@example.com | åœ°å€ï¼šåŒ—äº¬å¸‚æµ·æ·€åŒº

ä¸ªäººç®€ä»‹
---------
æœ‰5å¹´è½¯ä»¶å¼€å‘ç»éªŒçš„å…¨æ ˆå·¥ç¨‹å¸ˆï¼Œä¸“æ³¨äºWebåº”ç”¨å¼€å‘å’Œäººå·¥æ™ºèƒ½åº”ç”¨ã€‚å…·æœ‰æ‰å®çš„ç¼–ç¨‹åŸºç¡€å’Œä¸°å¯Œçš„é¡¹ç›®ç»éªŒï¼Œèƒ½å¤Ÿç‹¬ç«‹å®Œæˆä»éœ€æ±‚åˆ†æåˆ°ç³»ç»Ÿå®ç°çš„å…¨è¿‡ç¨‹ã€‚

æ•™è‚²èƒŒæ™¯
---------
åŒ—äº¬å¤§å­¦ | è®¡ç®—æœºç§‘å­¦ | ç¡•å£« | 2015-2018
æ¸…åå¤§å­¦ | è½¯ä»¶å·¥ç¨‹ | å­¦å£« | 2011-2015

å·¥ä½œç»éªŒ
---------
é˜¿é‡Œå·´å·´ | é«˜çº§è½¯ä»¶å·¥ç¨‹å¸ˆ | 2020-è‡³ä»Š
- è´Ÿè´£ç”µå•†å¹³å°çš„åç«¯å¼€å‘ï¼Œä½¿ç”¨Javaå’ŒSpring Bootæ„å»ºå¾®æœåŠ¡æ¶æ„
- ä¼˜åŒ–äº†è®¢å•å¤„ç†ç³»ç»Ÿï¼Œæé«˜äº†30%çš„å¤„ç†æ•ˆç‡
- æ”¹è¿›äº†CI/CDæµç¨‹ï¼Œå®ç°äº†è‡ªåŠ¨åŒ–æµ‹è¯•ï¼Œä¼˜åŒ–äº†æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½

è…¾è®¯ | è½¯ä»¶å·¥ç¨‹å¸ˆ | 2018-2020
- å‚ä¸ç¤¾äº¤åº”ç”¨çš„å‰ç«¯å¼€å‘ï¼Œä½¿ç”¨Reactå’ŒReduxæ„å»ºç”¨æˆ·ç•Œé¢
- å®ç°äº†å®æ—¶èŠå¤©åŠŸèƒ½ï¼Œæå‡äº†ç”¨æˆ·ä½“éªŒ
- å¼€å‘äº†10+ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œå‡å°‘äº†50%çš„é¡µé¢åŠ è½½æ—¶é—´ï¼Œå®ç°äº†å“åº”å¼è®¾è®¡

æŠ€èƒ½
---------
ç¼–ç¨‹è¯­è¨€ï¼šPython, Java, JavaScript, HTML/CSS
å‰ç«¯æŠ€æœ¯ï¼šReact, Vue, Redux, Webpack
åç«¯æŠ€æœ¯ï¼šSpring Boot, Node.js, Django, RESTful API
æ•°æ®åº“ï¼šMySQL, MongoDB, Redis
DevOpsï¼šDocker, Kubernetes, Git, CI/CD
äº‘æœåŠ¡ï¼šAWS, Azure
å…¶ä»–ï¼šå¾®æœåŠ¡æ¶æ„, æ•æ·å¼€å‘, è®¾è®¡æ¨¡å¼

é¡¹ç›®ç»éªŒ
---------
ç”µå•†å¹³å°ä¼˜åŒ– | é˜¿é‡Œå·´å·´ | 2021-2022
- é‡æ„äº†ç”µå•†å¹³å°çš„è®¢å•å¤„ç†ç³»ç»Ÿï¼Œä½¿ç”¨å¾®æœåŠ¡æ¶æ„æé«˜äº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œæ€§èƒ½
- ä½¿ç”¨Java, Spring Boot, MySQL, Redis, Dockerç­‰æŠ€æœ¯
- ç³»ç»Ÿæ€§èƒ½æå‡40%ï¼Œæ”¯æŒæ¯ç§’å¤„ç†1000+è®¢å•

ç¤¾äº¤åª’ä½“åº”ç”¨ | è…¾è®¯ | 2019-2020
- å¼€å‘äº†ä¸€ä¸ªç¤¾äº¤åª’ä½“åº”ç”¨çš„å‰ç«¯ï¼Œå®ç°äº†å®æ—¶èŠå¤©ã€åŠ¨æ€å‘å¸ƒç­‰åŠŸèƒ½
- ä½¿ç”¨React, Redux, WebSocket, CSS3, HTML5ç­‰æŠ€æœ¯
- åº”ç”¨è·å¾—äº†è¶…è¿‡100ä¸‡ç”¨æˆ·ï¼Œç”¨æˆ·æ»¡æ„åº¦è¾¾åˆ°95%

è¯­è¨€èƒ½åŠ›
---------
ä¸­æ–‡ï¼šæ¯è¯­
è‹±è¯­ï¼šæµåˆ©

è¯ä¹¦
---------
AWS Certified Solutions Architect | 2021
Oracle Certified Professional Java Programmer | 2019
"""
    
    # åˆ›å»ºç¤ºä¾‹ç®€å†æ–‡ä»¶ï¼ˆWordæ ¼å¼ï¼‰
    output_file = os.path.join(output_dir, 'example_resume.docx')
    
    # ç”±äºåœ¨äº‘ç«¯ç¯å¢ƒä¸­å¯èƒ½æ— æ³•åˆ›å»ºWordæ–‡æ¡£ï¼Œè¿™é‡Œåˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(resume_content)
    
    return output_file

#################################################
# ä¸»å‡½æ•°
#################################################

def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡ŒStreamlitåº”ç”¨"""
    st.title("AIç®€å†èŒä½åŒ¹é…ç³»ç»Ÿ")
    st.subheader("ä½¿ç”¨AIåˆ†æç®€å†å¹¶åŒ¹é…æœ€é€‚åˆçš„èŒä½")
    
    # åˆå§‹åŒ–åº”ç”¨
    app = ResumeJobMatcherApp()
    
    # åˆ›å»ºç¤ºä¾‹ç®€å†
    data_dir = "./data"
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
    
    example_resume_path = os.path.join(data_dir, 'example_resume.docx')
    if not os.path.exists(example_resume_path):
        try:
            example_resume_path = create_example_resume_file(data_dir)
            st.success("å·²åˆ›å»ºç¤ºä¾‹ç®€å†æ–‡ä»¶")
        except Exception as e:
            st.error(f"åˆ›å»ºç¤ºä¾‹ç®€å†å¤±è´¥: {str(e)}")
    
    # åˆ›å»ºä¾§è¾¹æ 
    st.sidebar.title("æ“ä½œé¢æ¿")
    
    # ä¸Šä¼ ç®€å†
    st.sidebar.header("ä¸Šä¼ ç®€å†")
    uploaded_file = st.sidebar.file_uploader("é€‰æ‹©ç®€å†æ–‡ä»¶", type=['pdf', 'docx', 'txt'])
    
    # ä½¿ç”¨ç¤ºä¾‹ç®€å†é€‰é¡¹
    use_example = st.sidebar.checkbox("ä½¿ç”¨ç¤ºä¾‹ç®€å†", value=True)
    
    # èŒä½æœç´¢é€‰é¡¹
    st.sidebar.header("èŒä½æœç´¢")
    job_keywords = st.sidebar.text_input("èŒä½å…³é”®è¯", value="è½¯ä»¶å·¥ç¨‹å¸ˆ")
    job_location = st.sidebar.text_input("å·¥ä½œåœ°ç‚¹", value="åŒ—äº¬")
    job_limit = st.sidebar.slider("æœç´¢ç»“æœæ•°é‡", min_value=5, max_value=20, value=10)
    
    # åœ¨äº‘ç«¯ç¯å¢ƒä¸­é»˜è®¤ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
    use_api = st.sidebar.checkbox("ä½¿ç”¨çœŸå®APIæ•°æ®", value=False, 
                                help="åœ¨äº‘ç«¯ç¯å¢ƒä¸­å¯èƒ½å—é™ï¼Œå»ºè®®ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
    
    # å¤„ç†æŒ‰é’®
    if st.sidebar.button("å¼€å§‹åŒ¹é…"):
        # æ˜¾ç¤ºå¤„ç†ä¸­æç¤º
        with st.spinner("æ­£åœ¨å¤„ç†ä¸­..."):
            # ç¡®å®šä½¿ç”¨çš„ç®€å†æ–‡ä»¶
            resume_file_path = None
            if uploaded_file is not None:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
                temp_file_path = os.path.join("./cache", uploaded_file.name)
                with open(temp_file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                resume_file_path = temp_file_path
                st.sidebar.success(f"å·²ä¸Šä¼ ç®€å†: {uploaded_file.name}")
            elif use_example:
                resume_file_path = example_resume_path
                st.sidebar.info("ä½¿ç”¨ç¤ºä¾‹ç®€å†")
            
            if resume_file_path:
                try:
                    # è¿è¡Œå®Œæ•´æµç¨‹
                    results = app.run_full_process(
                        resume_file_path=resume_file_path,
                        job_keywords=job_keywords,
                        location=job_location,
                        use_api=use_api,
                        limit=job_limit
                    )
                    
                    if results['success']:
                        # æ˜¾ç¤ºç»“æœ
                        display_results(results)
                    else:
                        st.error(f"å¤„ç†å¤±è´¥: {results['error']}")
                except Exception as e:
                    st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                    st.info("æç¤º: å¦‚æœæ˜¯èµ„æºä¸è¶³é”™è¯¯ï¼Œè¯·å°è¯•å‡å°‘æœç´¢ç»“æœæ•°é‡æˆ–ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            else:
                st.error("è¯·ä¸Šä¼ ç®€å†æ–‡ä»¶æˆ–é€‰æ‹©ä½¿ç”¨ç¤ºä¾‹ç®€å†")

def display_results(results):
    """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
    # æå–æ•°æ®
    resume_data = results['resume_data']
    jobs = results['jobs']
    match_results = results['match_results']
    
    # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
    col1, col2, col3 = st.columns([1, 1, 2])
    
    # ç¬¬ä¸€åˆ—ï¼šç®€å†æ‘˜è¦
    with col1:
        st.header("ç®€å†æ‘˜è¦")
        
        # ä¸ªäººä¿¡æ¯
        if 'personal_info' in resume_data:
            personal = resume_data['personal_info']
            st.subheader("ä¸ªäººä¿¡æ¯")
            st.write(f"å§“å: {personal.get('name', 'æœªçŸ¥')}")
            st.write(f"ç”µè¯: {personal.get('phone', 'æœªçŸ¥')}")
            st.write(f"é‚®ç®±: {personal.get('email', 'æœªçŸ¥')}")
        
        # æ•™è‚²èƒŒæ™¯
        if 'education' in resume_data and resume_data['education']:
            st.subheader("æ•™è‚²èƒŒæ™¯")
            for edu in resume_data['education']:
                st.write(f"{edu.get('school', 'æœªçŸ¥')} - {edu.get('degree', 'æœªçŸ¥')} - {edu.get('major', 'æœªçŸ¥')}")
                if 'start_date' in edu and 'end_date' in edu:
                    st.write(f"{edu.get('start_date', '')} è‡³ {edu.get('end_date', '')}")
                st.write("---")
        
        # æŠ€èƒ½
        if 'skills' in resume_data and resume_data['skills']:
            st.subheader("æŠ€èƒ½")
            st.write(", ".join(resume_data['skills'][:10]))
    
    # ç¬¬äºŒåˆ—ï¼šæœç´¢åˆ°çš„èŒä½
    with col2:
        st.header("æœç´¢åˆ°çš„èŒä½")
        st.write(f"å…³é”®è¯: {jobs[0].get('keywords', ['æ— å…³é”®è¯'])[:5]}")
        st.write(f"å…±æ‰¾åˆ° {len(jobs)} ä¸ªèŒä½")
        
        for i, job in enumerate(jobs[:3]):
            st.subheader(f"{i+1}. {job.get('title', 'æœªçŸ¥èŒä½')}")
            st.write(f"å…¬å¸: {job.get('company', 'æœªçŸ¥å…¬å¸')}")
            st.write(f"åœ°ç‚¹: {job.get('location', 'æœªçŸ¥åœ°ç‚¹')}")
            st.write(f"è¦æ±‚æŠ€èƒ½: {', '.join(job.get('required_skills', ['æ— '])[:5])}")
            st.write("---")
        
        if len(jobs) > 3:
            st.write("...")
    
    # ç¬¬ä¸‰åˆ—ï¼šåŒ¹é…ç»“æœ
    with col3:
        st.header("åŒ¹é…ç»“æœ")
        st.write("æŒ‰åŒ¹é…åº¦æ’åºçš„èŒä½åˆ—è¡¨")
        
        for i, match in enumerate(match_results[:5]):
            # åˆ›å»ºå¯å±•å¼€çš„éƒ¨åˆ†
            with st.expander(f"{i+1}. {match.get('job_title', 'æœªçŸ¥èŒä½')} - åŒ¹é…åº¦: {match.get('overall_match', 0):.2f}"):
                st.write(f"å…¬å¸: {match.get('company', 'æœªçŸ¥å…¬å¸')}")
                
                # æ˜¾ç¤ºåŒ¹é…è¯¦æƒ…
                st.subheader("åŒ¹é…è¯¦æƒ…")
                col_a, col_b = st.columns(2)
                with col_a:
                    st.write(f"æ–‡æœ¬ç›¸ä¼¼åº¦: {match.get('text_similarity', 0):.2f}")
                    st.write(f"å…³é”®è¯åŒ¹é…: {match.get('keyword_match', 0):.2f}")
                    st.write(f"æŠ€èƒ½åŒ¹é…: {match.get('skill_match', 0):.2f}")
                with col_b:
                    st.write(f"æ•™è‚²èƒŒæ™¯åŒ¹é…: {match.get('education_match', 0):.2f}")
                    st.write(f"å·¥ä½œç»éªŒåŒ¹é…: {match.get('experience_match', 0):.2f}")
                
                # æ˜¾ç¤ºåŒ¹é…çš„æŠ€èƒ½
                if 'matched_skills' in match and match['matched_skills']:
                    st.subheader("åŒ¹é…çš„æŠ€èƒ½")
                    st.write(", ".join(match['matched_skills']))
                
                # æ·»åŠ ç”³è¯·æŒ‰é’®ï¼ˆç¤ºä¾‹åŠŸèƒ½ï¼‰
                if st.button(f"ç”³è¯·è¯¥èŒä½ #{i+1}"):
                    st.success("å·²å‘é€ç”³è¯·ï¼ï¼ˆç¤ºä¾‹åŠŸèƒ½ï¼‰")
    
    # æ·»åŠ ä¸‹è½½ç»“æœæŒ‰é’®
    st.download_button(
        label="ä¸‹è½½åŒ¹é…ç»“æœ",
        data=json.dumps(match_results, ensure_ascii=False, indent=4),
        file_name="match_results.json",
        mime="application/json",
    )

if __name__ == "__main__":
    main()
